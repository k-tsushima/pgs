% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{subfig}
\usepackage{lmodern}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\pgfplotsset{compat=1.12}

\setlength{\parindent}{0pt}
\renewcommand{\indent}{\hspace*{0pt}}

\newcommand{\tab}{\hspace*{5mm}}
\newcommand{\qtab}{\hspace*{5mm} \ \quad}

\newcommand{\sif}[3]{\text{if } #1 \text{ then } #2 \text{ else } #3}
\newcommand{\product}[2]{#1 \times #2}
\newcommand{\tuple}[2]{(#1 :: #2)}
\newcommand{\rearrs}[3]{RearrS \ #1 \ #2 \ #3}
\newcommand{\rearrv}[3]{RearrV \ #1 \ #2 \ #3}
\newcommand{\casebx}[4]{Case \ #1 \ #2 \ #3 \ #4}

\newcommand{\putbx}[3]{put \, [\![#1]\!] \ #2 \ #3}
\newcommand{\putbxinline}[1]{put \, [\![#1]\!]}
\newcommand{\getbx}[2]{get \, [\![#1]\!] \ #2}
\newcommand{\getbxinline}[1]{get \, [\![#1]\!]}

\newcommand{\putrev}[3]{put_{REV} \, [\![#1]\!] \ {#2} \ {#3}}
\newcommand{\getrev}[2]{get_{REV} \, [\![#1]\!] \ {#2}}

\newcommand{\pg}[3]{pg \, [\![#1]\!] (#2, #3)}
\newcommand{\pginline}[1]{pg \, [\![#1]\!]}

\newcommand{\cpg}[5]{cpg [\![#1]\!] (#2, #3, #4, #5)}
\newcommand{\cpginline}[1]{cpg \, [\![#1]\!]}

\newcommand{\kpg}[7]{kpg [\![#1]\!] (#2, #3, #4, #5, #6, #7)}
\newcommand{\kpginline}[1]{kpg \, [\![#1]\!]}

\newcommand{\xpg}[3]{xpg \, [\![#1]\!] (#2, #3)}
\newcommand{\xpginline}[1]{xpg \, [\![#1]\!]}

\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}

\begin{document}
%
\title{An efficient composition of bidirectional programs
  by tupling and lazy updates 
%  tupling
%  accumulating updates = lazy updates
%  based on the idea of reversible computing  
  % \thanks{Supported by organization x.}
}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
15--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%

Points to discuss
\begin{itemize}
\item Schedule:
\item Introduction (story), Contribution, positions, examples, beginning of September?
\item zero draft : mid of September 
  
\item When will be the deadline of PEPM2020 (October 18th)
\item ESOP (?)
\item Need to change the style file of latex..
\item []


\item Related work?
\item 

\item TODO: %relationship between result (original vs \{cpg, kpg, xpg\})
%\item right assoc \& Recursive example?
%\item current foldr is not efficient? Are there any efficient foldr? Question to Prof. Hu.
%\item Language to show semantics: fi?, $f^{-1}$, $cond_{sv}$ and $cond_{s}$
%\item A good simple example of bx: Used in explanation of BiGUL and evaluation of pg.
%\item Related work: suggest?
%\item another pg ?? should be compared?
\end{itemize}

\section{Introduction}

%\begin{itemize}
%\item Importance of BX, BX is a solution of view update problem in database.
%\item goodness of 
%\item Explanation of put-based BX: BiGUL.
%\item Current status of BiGUL: Fastest BX language in the world
%\item But there is a problem: Efficiency of compose evaluation. The current implementation of BiGUL does not save the intermediate states, the number of get is quadratic. This is not good.
%\item To solve this problem we use an idea: introduce pg : combination of put and get. Then, no information will be lost in a specific condition.
%  an idea from reversible computation: not to lose any information.
%\item We extend pg with several ideas to produce faster implementation.
%\item 
%\end{itemize}

%\begin{itemize}
%\item Importance of BX, BX is a solution of view update problem in database.
%\item goodness of 
%\item Explanation of put-based BX: BiGUL.
%\item Current status of BiGUL: Fastest BX language in the world
%\item But there is a problem: Efficiency of compose evaluation. The current implementation of BiGUL does not save the intermediate states, the number of get is quadratic. This is not good.
%\item To solve this problem we use an idea: introduce pg : combination of put and get. Then, no information will be lost in a specific condition.
%  an idea from reversible computation: not to lose any information.
%\item We extend pg with several ideas to produce faster implementation.
%\item 
%\end{itemize}

In software, there are strong demands for synchronizing the data. In database community it is known as ``view update problem'' and researched for a long time \cite{}.
% A Survey to View Update Problem 
As a solution for this problem, bidirectional transformation is introduced \cite{}. It enables the evaluation of source updating: ``put'' produces the updated source from the original source and the updated view.
% The first paper of bidirectional transformation

There are two types of bidirectional transformation. One is get-based bidirectional transformation \cite{} that receives the definition of $get$ and provides $put$. A problem of this approach is that it is possible to derive many correct $put$s. To choose one put, hulistics and programmer's intentions are needed. Another approach is put-based bidirectional transformation \cite{} that received the definition of $put$ and provide $get$. From a $put$ we can derive an unique $get$. 

BiGUL \cite{} is one of put-based bidirectional transformation language. It is fastest bidirectional language in the world now. However, it contains a problem when the BiGUL programs including many compositions. BiGUL does not store the intermediate states when $get$s are re-evaluated so many times. In this case the number of get is quadratic.

\vspace{5mm}

Figure that shows many gets re-evaluation 

\vspace{5mm}

To solve this problem and make BiGUL evaluation efficient, we use two techniques. The first technique is tupling, well-known technique for efficiency \cite{}. Its basic idea is to reduce the common computations by combining two evaluations. In our work, we combines the evaluation of $put$ and $get$, and introduce $pg$. Thanks to tupling, we do not lose information like intermediate states.
The second technique is lazy update and lazy computation. $pg$ itself includes some inefficiency. For removing the inefficiency we do the update and computation lazily.

The rest of this paper is the following. We introduce a subset of BiGUL, miniBiGUL, and show syntax, semantics, and properties in Section 2. Combining the semantics of put and get in Section 2, we construct $pg$ and show that it is self-inverse in Section 3.
We apply three optimizations to $pg$ in sequence. The first one is keeping update of BX lazily, and obtain $cpg$ in Section 4. The second one is lazy evaluation to avoid redundant computation, and obtain $kpg$ in Section 5. The third one is combination of $pg$ and $kpg$ in Section 6, because they are strong for different type of programs. In Section 7, we show experiemntal result of $pg$, $cpg$, $kpg$, $xpg$ and the original miniBiGUL.
In Section 8 we discuss about related work, and conclude in Section 9.


% Story ->
% reversible is needed not to lose any information -> pg is introduced.
% pg is not good for lassoc -> cpg (xpg_2) is introduced.
% cpg can be improved -> kpg(xpg) is introduced.
% kpg is slower than pg for rassoc. combined version -> xpg.

% Evaluation result: Comparison with OCaml implementation of minBiGUL

%\begin{itemize}
%\item Importance of BX, BX is a solution of view update problem in database.
%\item Explanation of put-based BX: BiGUL.
%\item Current status of BiGUL: Fastest BX language in the world
%\item But there is a problem: Efficiency of compose evaluation. The current implementation of BiGUL does not save the intermediate states, the number of get is quadratic. This is not good.
%\item To solve this problem we use an idea: introduce pg : combination of put and get. Then, no information will be lost in a specific condition.
%  an idea from reversible computation: not to lose any information.
%\item We extend pg with several ideas to produce faster implementation.
%\item 
%\end{itemize}

\subsection{Contribution}

\begin{itemize}
\item Improvement of evaluation efficiency
  \begin{itemize}
  \item Quadratic to exponential? 
  \item The introduced extentions (maybe) use more memory than the original approach, but they are faster than the original.
  \end{itemize}
\item Tupling is also effective in bidirectional programming.
  \begin{itemize}
  \item A pair of put and get is self-inverse (involution).
  \end{itemize}
\item lazy update \& lazy computation is also good optimization for BX.
%\item Reveal a part of relationship between BX and Reversible.
%  \begin{itemize}
%  \item Very well-behaved (no adaptive-case) \& The same evaluation path $\to$ No garbage Reversible Computation.
%  \item 
%  \item If we can obtain good parameter (dummy) for a BiGUL program,
%    put(s, dummy) can be a complement function.
  \end{itemize}

\subsection{Construction of this paper}

\begin{itemize}
\item BiGUL 
\item pg (pair of put and get)
\item cpg (extention of pg. Keep eval information for reusing)
\item kpg (extention of cpg. Lazy evaluation)
\item xpg (combination of pg and kpg)
\item Experiment
\item Related work
\item Conclusion and Future work
\end{itemize}

\section{Bidirectional Programming Language: minBiGUL}

MinBiGUL, our target language in this paper, is a subset of BiGUL [?] which is a simple yet powerful putback-based bidirectional language. BiGUL supports two transformations: a forward transformation $get$ producing a view from a source and a backward transformation $put$ taking a source and a modified view to produce an updated source. Intuitively, if we have a BiGUL program $bx$, these two transformations are following functions:\\
    $\tab \getbxinline{bx} = fun \ s \to v \\
    \tab \putbxinline{bx} = fun \ s \ v \to v$

BiGUL is well-behaved since two functions $\putbxinline{bx}$ and $\getbxinline{bx}$ satify the round-trip laws as follows:\\
    $\tab \putbx{bx}{s}{(\getbx{bx}{s})} = s \qquad [\text{GETPUT}]\\
    \tab \getbx{bx}{(\putbx{bx}{s}{v})} = v \qquad [\text{PUTGET}]$

The GETPUT law means that if there is no change to the view, there should be no change to the source. The PUTGET law means that we can recover the modified view by applying the forward transformation to the updated source.

MinBiGUL inherited from BiGUL also supports transformations $put$ and $get$ which are satify two above laws. In addition, we restrict adaptive cases of BiGUL on minBiGUL. Then $put$ and $get$ satify one more law, PUTPUT, like the following:\\
    $\tab \putbx{bx}{(\putbx{bx}{s}{v'})}{v} = \putbx{bx}{s}{v} \qquad [\text{PUTPUT}]$

The PUTPUT law means that a source update should overwrite the effect of previous source updates.

Due to the satisfaction of three laws, GETPUT, PUTGET and PUTPUT, minBiGUL is very well-behaved.

In the remaining of this section, we will present about the syntax and semantics of minBiGUL through formal definitions and examples.

\subsection{Syntax}

The syntax of minBiGUL is briefly written as follows:

$bx := Skip \ h \\ 
    \qtab | \ Replace \\ 
    \qtab | \ Prod \ bx_1 \ bx_2 \\ 
    \qtab | \ RearrS \ f_1 \ f_2 \ bx \\
    \qtab | \ RearrV \ g_1 \ g_2 \ bx \\
    \qtab | \ Case \ cond_{sv} \ cond_{s} \ bx_1 \ bx_2 \\ 
    \qtab | \ Compose \ bx_1 \ bx_2$

A minBiGUL program may be either a skip of a function or a replacement or a product of two minBiGUL programs or a source / view rearrangement or a case combinatator without adaptive cases or a composition of some minBiGUL programs.

For source / view rearrangement, BiGUL use just one lambda expression to express how to deconstruct as well as reconstruct data. It is a kind of bijection. However, to be able to implement it in OCaml, the environment used for developing minBiGUL and solutions in the paper, we need give two functions which one is the inverse of the other. In the above syntax, $f_2 = f_1^{-1}$ and $g_2 = g_1^{-1}$.

To help make demonstration more direct, we provide the following alternatives representation:

    $\tab Prod \ bx_1 \ bx_2 \equiv bx_1 \times bx_2$\\
    $\tab Compose \ bx_1 \ bx_2 \equiv bx_1 \circ bx_2$

In general, $\circ$ has a higher priority than $\times$. Since only consider a product of two minBiGUL programs is considered, it is unnecessary to define the associativity precedence of $\times$. The one of $\circ$ may be left or right, however we do not declare the default.

In the next part, we will introduce the semantics of minBiGUL.

\subsection{Semantics}

\begin{definition}
    $\putbx{bx}{s}{v}$

    $\putbx{Skip \ h}{s}{v} = \sif{h \ s = v}{s}{\text{fail}}$

    $\putbx{Replace}{s}{v} = v$

    $\putbx{\product{bx_1}{bx_2}}{(s_1, s_2)}{(v_1, v_2)} =\\
        \tab ((\putbx{bx_1}{s_1}{v_1}),(\putbx{bx_2}{s_2}{v_2}))$

    $\putbx{\rearrs{f_1}{f_2}{bx}}{s}{v} = f_2 \ (\putbx{bx}{(f_1 \ s)}{v})$

    $\putbx{\rearrv{g_1}{g_2}{bx}}{s}{v} = \putbx{bx}{s}{(g_1 \ v)}$

    $\putbx{\casebx{cond_{sv}}{cond_{s}}{bx_1}{bx_2}}{s}{v} = \\
        \tab \text{if} \ {cond_{sv} \ s \ v} \\
        \tab \text{then} \ s' \Leftarrow \putbx{bx_1}{s}{v} \\
        \tab \text{else} \ s' \Leftarrow \putbx{bx_2}{s}{v} \\
        \tab \text{fi} \ cond_{s} \ s'; \ \text{return} \ s'$

    $\putbx{bx_1 \circ bx_2}{s}{v} = \putbx{bx_1}{s}{(\putbx{bx_2}{(\getbx{bx_1}{s})}{v})}$
\end{definition}

\begin{definition}
    $\getbx{bx}{s}$

    $\getbx{Skip \ h}{s} = h \ s$

    $\getbx{Replace}{s} = s$

    $\getbx{\product{bx_1}{bx_2}}{(s_1,s_2)} = \\
        \tab ((\getbx{bx_1}{s_1}),(\getbx{bx_2}{s_2}))$

    $\getbx{\rearrs{f_1}{f_2}{bx}}{s} = \getbx{bx}{(f_1 \ s)}$

    $\getbx{\rearrv{g_1}{g_2}{bx}}{s} = g_2 \ (\getbx{bx}{s})$

    $\getbx{\casebx{cond_{sv}}{cond_{s}}{bx_1}{bx_2}}{s} =\\
        \tab \text{if} \ {cond_{s} \ s}\\
        \tab \text{then} \ v' \Leftarrow \getbx{bx_1}{s}\\
        \tab \text{else} \ v' \Leftarrow \getbx{bx_2}{s}\\
        \tab \text{fi} \ {cond_{sv} \ s \ v'}; \ \text{return} \ v'$

    $\getbx{bx_1 \circ bx_2}{s} = \getbx{bx_2}{(\getbx{bx_1}{s})}$
\end{definition}

In defintions 1 and 2, we use if-then-else-fi statements to express semantics of $\putbxinline{Case}$ and $\getbxinline{Case}$. Statement (if $E_1$ then $X_1$ else $X_2$ fi $E_2$) means if the test $E_1$ is true, the statement $X_1$ is executed and the assertion $E_2$ must be true, otherwise, i.e. $E_2$ is false, the statement $X_2$ is executed and the assertion $E_2$ must be false. If the values of $E_1$ and $E_2$ are distinct, the if-then-else-fi structure is undefined. We can write the equivalent if-then-else statement as follows:

$\tab \text{if } E_1 \text{ then } X_1 \text{ else } X_2 \text{ fi } E_2; S\\
\tab \equiv \text{if }E_1 = true \text{ then}\\ 
    \qtab \tab X_1;\\ 
    \qtab \tab \text{if } E_2 = true \text{ then } S \text{ else assert } false;\\
    \qtab \text{else}\\ 
    \qtab \tab X_2;\\ 
    \qtab \tab \text{if } E_2 = false \text{ then } S \text{ else assert } false;$

The if-then-else-fi statement is useful to describe many functions related to $Case$ in this paper.

Next, let's take a look at some examples to better understand about minBiGUL. We start with quite obivious things as follows:\\
$\putbx{Skip \ (\lambda x.(x*x))}{10}{100} = 10$\\
$\putbx{Skip \ (\lambda \_.())}{1}{()} = 1$\\ 
$\getbx{Skip \ (\lambda x.(x*x))}{10} = 100$\\
$\getbx{Skip \ (\lambda \_.())}{1} = ()$\\
$\putbx{Replace}{1}{100} = 100$\\
$\getbx{Replace}{1} = 1$\\

Now, let's consider the definition of $phead$ in BiGUL [?]:

$\tab phead :: Show \ s \Rightarrow BiGUL \ [s] \ s\\
\tab phead = \$(RearrS \ [\![\lambda(s:ss) \to (s,ss)]\!])\$\\
    \qtab \qtab \quad \$(RearrV \ [\![\lambda v \to (v,())]\!])\$\\
        \qtab \qtab \qquad Replace \ `prod\text{'} \ (Skip \ (const \ ()))$

The above program rearranges the source, a non-empty list, to a pair of its head element $s$ and its tail $ss$, and the view to a pair $(v, ())$, then we can use $v$ to replace $s$ and $()$ to keep $ss$. $\putbx{phead}{s_0}{v_0}$ returns a list whose head is $v_0$ and tail is the tail of $s_0$. $\getbx{phead}{s_0}$ returns the head of $s_0$. For instance, $\putbx{phead}{[1,2,3]}{100} = [100,2,3]$ and $\getbx{phead}{[1,2,3]} = 1$.\\

In minBiGUL, we can express $phead$ as follows:

$\tab phead = RearrS \ f_1 \ f_2 \ bx_s \ \text{where:}\\
    \qtab f_1 = \lambda (s::ss).(s,ss)\\
    \qtab f_2 = \lambda (s,ss).(s::ss)\\
    \qtab bx_s = RearrV \ g_1 \ g_2 \ bx_v \ \text{where:}\\
        \qtab \qtab g_1 = \lambda v.(v,())\\
        \qtab \qtab g_2 = \lambda (v,()).v\\
        \qtab \qtab bx_v = \product{Replace}{(Skip \ (\lambda \_.())}$\\

Then, we can evaluate $\putbxinline{phead}$ and $\getbxinline{phead}$ based on their definitions:

$\putbx{phead}{[1,2,3]}{100}\\
\tab = \putbx{\rearrs{f_1}{f_2}{bx_s}}{[1,2,3]}{100}\\
\tab = f_2 \ (\putbx{bx_s}{(f_1 \ [1,2,3])}{100})\\
\tab = f_2 \ (\putbx{\rearrv{g_1}{g_2}{bx_v}}{(1,[2,3])}{100})\\
\tab = f_2 \ (\putbx{bx_v}{(1,[2,3])}{(g_1 \ 100}))\\
\tab = f_2 \ (\putbx{\product{Replace}{(Skip \ (\lambda \_.()))}}{(1,[2,3])}{(100,())})\\
\tab = f_2 \ ((\putbx{Replace}{1}{100}), (\putbx{(Skip \ (\lambda \_.()))}{[2,3]}{()}))\\
\tab = f_2 \ (100, [2,3])\\
\tab = [100,2,3]$\\

$\getbx{phead}{[1,2,3]}\\
\tab = \getbx{\rearrs{f_1}{f_2}{bx_s}}{[1,2,3]}\\
\tab = \getbx{bx_s}{(f_1 \ [1,2,3])}\\
\tab = \getbx{\rearrv{g_1}{g_2}{bx_v}}{(1,[2,3])}\\
\tab = g_2 \ (\getbx{bx_v}{(1,[2,3])})\\
\tab = g_2 \ (\getbx{\product{Replace}{(Skip \ (\lambda \_.()))}}{(1,[2,3])})\\
\tab = g_2 \ ((\getbx{Replace}{1}), (\getbx{(Skip \ (\lambda \_.()))}{[2,3]}))\\
\tab = g_2 \ (1,())\\
\tab = 1$\\

If we wanna update the head element of the head element of a list of lists by using the view, we can define a composition like $phead \circ phead$. For example:

    \tab $\putbx{phead \circ phead}{[[1,2,3],[\,],[4,5]]}{100} = [[100,2,3],[\,],[4,5]]$\\
    \tab $\getbx{phead \circ phead}{[[1,2,3],[\,],[4,5]]} = 1$\\

We distingwish two $phead$s in the composition by indices. According to definitions of $\putbxinline{bx}$ and $\getbxinline{bx}$, we have:

$\getbx{phead_1 \circ phead_2}{[[1,2,3],[\,],[4,5]]}\\
    \tab = \getbx{phead_2}{(\getbx{phead_1}{[[1,2,3],[\,],[4,5]]})}\\
    \tab = \getbx{phead_2}{[1,2,3]}\\
    \tab = 1$\\

$\putbx{phead_1 \circ phead_2}{[[1,2,3],[\,],[4,5]]}{100}\\
    \tab = \putbx{phead_1}{[[1,2,3],[\,],[4,5]]}{(\putbx{phead_2}{(\getbx{phead_1}{[[1,2,3],[\,],[4,5]]})}{100})}\\
    \tab = \putbx{phead_1}{[[1,2,3],[\,],[4,5]]}{(\putbx{phead_2}{[1,2,3]}{100})}\\
    \tab = \putbx{phead_1}{[[1,2,3],[\,],[4,5]]}{[100,2,3]}\\
    \tab = [[100,2,3],[\,],[4,5]]$\\

One more example we would like to present is $replaceAll$ whose definition in BiGUL as follows:\\
$\tab replaceAll :: (Eq \ s, Show \ s) \Rightarrow BiGUL \ [s] \ s \\ 
\tab replaceAll = Case \ [\\
    \qtab \$(normal \ [\![\lambda s \ v \to length \ s == 1]\!][\![\lambda s \to length \ s == 1]\!]) \\ 
    \qtab \Longrightarrow \$(rearrS \ [\![\lambda [x] \to x]\!]) Replace,\\
    \qtab \$(normal \ [\![\lambda s \ v \to length \ s > 1]\!][\![\lambda s \to length \ s > 1]\!]) \\ 
    \qtab \Longrightarrow \$(rearrS \ [\![\lambda (x:xs) \to (x,xs)]\!])\$\\ 
    \qtab \qtab \$(rearrV \ [\![\lambda v \to (v,v)]\!])\$\\ 
    \qtab \qtab Replace \ `prod\text{'} \ replaceAll\\
\tab ]$\\

The following expresses $replaceAll$ in minBiGUL:\\
$\tab replaceAll = Case \ cond_{sv} \ cond_{s} \ bx_1 \ bx_2 \ \text{where:}\\ 
    \qtab cond_{sv} = \lambda s.\lambda v.length \ s == 1\\
    \qtab cond_{s} = \lambda s.length \ s == 1\\ 
    \qtab bx_1 = RearrS \ (\lambda [x] \to x) \ (\lambda x \to [x]) \ Replace\\ 
    \qtab bx_2 = RearrS \ (\lambda (x::xs) \to (x,xs)) \ (\lambda (x,xs) \to (x::xs)) \ bx_s \ \text{where:}\\ 
        \qtab \tab bx_s = RearrV \ (\lambda v \to (v,v)) \ (\lambda (v,v) \to v) \ bx_v \ \text{where:}\\
            \qtab \qtab bx_v = \product{Replace}{replaceAll}$

We can also evaluate $\putbxinline{replaceAll}$ and $\getbxinline{replaceAll}$ similarly to the previous examples if we pay attention to conditions $cond_sv$ and $cond_s$ as well as the if-then-esle-fi structure. $\putbxinline{replaceAll}$ uses the view to update all elements in the source list, while $\getbxinline{replaceAll}$ returns the an element of the source list with same elements. For example, $\putbx{replaceAll}{[1,2,3]}{100} = [100,100,100]$ and $\getbx{replaceAll}{[1,1,1]} = 1$.

\section{pg}
\subsection{Self-inverse function: pg}

In minBiGUL or even BiGUL, when evaluating a composition of many programs, $get$s are re-evaluated so many times since no intermediate state is stored during the evaluation. This is a kind of information loss. One question is whether it is possible to calculate such programs without losing information. And the answer is yes. It comes from the the idea of reversible computation where all information during the evaluation need to be kept. In minBiGUL, we can do that by tupling $put$ and $get$. A pair of a source and a view is accepted as the input of a function named $pg$ to produce a new pair that contains the actual result of a corresponding minBiGUL program.

\begin{definition}
    $\pg{bx}{s}{v} = (\putbx{bx}{s}{v}, \getbx{bx}{s})$
\end{definition}

$pg$ is an involution that is self-inverse. An involution is a function $f$ that satifies $f(f(x)) = x \text{ for all } x \text{ in the domain of } f$.

\begin{proof}
$pg [\![bx]\!] \ (\pg{bx}{s}{v}) \\
    \tab = \pg{bx}{(\putbx{bx}{s}{v})}{(\getbx{bx}{s})} \quad [pg \text{ definition}] \\
    \tab = (put \ [\![bx]\!] \ (\putbx{bx}{s}{v}) \ (\getbx{bx}{s}), \getbx{bx}{(\putbx{bx}{s}{v})})  \quad [pg \text{ definition}] \\
    \tab = (put \ [\![bx]\!] \ (\putbx{bx}{s}{v}, \getbx{bx}{s}), v) \quad [\text{PUTGET}] \\
    \tab = (put \ [\![bx]\!] \ (s, \getbx{bx}{s}), v) \quad [\text{PUTPUT}] \\
    \tab = (s, v) \quad [\text{GETPUT}]$
\end{proof}

\subsection{Construction of pg}

$\pg{Skip \ h}{s}{v} \\
    \tab = (\sif{h \ s = v}{s}{\text{fail}}, h \ s) \\
    \tab = \sif{h \ s = v}{(s, h \ s)}{\text{fail}} \\
    \tab = \sif{h \ s = v}{(s, v)}{\text{fail}}$

There is a trick in the construction of $\pginline{Skip \ h}$. The first equality is simply based on the definitions of $pg$, $\putbxinline{Skip \ h}$ and $\getbxinline{Skip \ h}$. The second one tuples two results of $put$ and $get$ in the body of the if-expression. And the last one is quite obivious. What we call the trick here is in the second equality where in some cases, the result of $pg$ may be fail although there is no fail when evaluating $\getbxinline{Skip \ h}$.\\

$\pg{Replace}{s}{v}\\
    \tab = (v, s)$

$\pg{\product{bx_1}{bx_2}}{(s_1,s_2)}{(v_1,v_2)} \\
    \tab = ((\putbx{bx_1}{s_1}{v_1}),(\putbx{bx_2}{s_2}{v_2}), (\getbx{bx_1}{s_1}), (\getbx{bx_2}{s_2})) \\
    \tab = (s_1, v_1) \Leftarrow \pg{bx_1}{s_1}{v_1}; \\
        \qtab (s_2, v_2) \Leftarrow \pg{bx_2}{s_2}{v_2}; \\
        \qtab \tab ((s_1,s_2), (v_1,v_2))$

$\pg{\rearrs{f_1}{f_2}{bx}}{s}{v} \\
    \tab = (f_2 \ (\putbx{bx}{(f_1 \ s)}{v}), \getbx{bx}{(f_1 \ s)}) \\
    \tab = (s, v) \Leftarrow \pg{bx}{f_1 \ s}{v};\\
        \qtab \tab (f_2 \ s, v)$

$\pg{\rearrv{g_1}{g_2}{bx}}{s}{v} \\
    \tab = (\putbx{bx}{s}{(g_1 \ v)}, g_2 \ (\getbx{bx}{s})) \\
    \tab = (s, v) \Leftarrow \pg{bx}{s}{g_1 \ v}; \\
        \qtab \tab (s, g_2 \ v)$\\

Constructions of $pg$ for the replacement, the product and the source / view rearrangements are very clear when just paring $put$ and $get$ respectively, then doing basic changes.\\

$\pg{\casebx{cond_{sv}}{cond_{s}}{bx_1}{bx_2}}{s}{v} \\
    \tab = (\text{if} \ {cond_{sv} \ s \ v} \\
    \qtab \text{then} \ s' \Leftarrow \putbx{bx_1}{s}{v} \\
    \qtab \text{else} \ s' \Leftarrow \putbx{bx_2}{s}{v} \\
    \qtab \text{fi} \ cond_{s} \ s'; \text{ return } s', \\
    \qtab \quad \text{if} \ {cond_{s} \ s}\\
    \qtab \quad \text{then} \ v' \Leftarrow \getbx{bx_1}{s}\\
    \qtab \quad \text{else} \ v' \Leftarrow \getbx{bx_2}{s}\\
    \qtab \quad \text{fi} \ {cond_{sv} \ s \ v'}; \text{ return } v') \\
    \tab = \text{if} \ {cond_{sv} \ s \ v} \ \&\& \ {cond_{s} \ s} \\
        \qtab \text{then} \ (s', v') \Leftarrow \pg{bx_1}{s}{v}\\
        \qtab \text{else} \ (s', v') \Leftarrow \pg{bx_2}{s}{v}\\
        \qtab \text{fi} \ cond_{s} \ s' \ \&\& \ cond_{sv} \ s \ v'; \text{ return } (s',v')$\\

A restriction for $\pginline{Case}$ needs to be introduced here. We know that there is one entering condition and one exit condition when evaluating $\putbxinline{Case}$ as well as $\getbxinline{Case}$. If a tupling $put$ and $get$ occurs, there will be 4 combinations of these conditions. This means that two entering conditions of $\putbxinline{Case}$ and $\getbxinline{Case}$ are not always simultaneously satified. The evaluated branches are distinct in the $put$ and $get$ directions for combinations $((cond_{sv} \ s \ v) \ \&\& \ (not (cond_{s} \ s)))$ and $((not (cond_{sv} \ s \ v) \ \&\& \ (cond_{s} \ s))$, which are restricted in this paper. This does not happen for the others which is used in the construction of $\pginline{Case}$ above. \\

$\pg{bx_1 \circ bx_2}{s}{v} \\
    \tab = (\putbx{bx_1}{s}{(\putbx{bx_2}{(\getbx{bx_1}{s})}{v})}, \getbx{bx_2}{(\getbx{bx_1}{s})}) \\
    \tab = v_1 \Leftarrow \getbx{bx_1}{s}; \\
        \qtab (s_2, v_2) \Leftarrow \pg{bx_2}{v_1}{v}; \\
        \qtab (s_3, v_3) \Leftarrow \pg{bx_1}{s}{s_2}; \\
            \qtab \tab (s_3, v_2) \\
    \tab = (s_1, v_1) \Leftarrow \pg{bx_1}{s}{dummy}; \\
        \qtab (s_2, v_2) \Leftarrow \pg{bx_2}{v_1}{v}; \\
        \qtab (s_3, v_3) \Leftarrow \pg{bx_1}{s}{s_2}; \\
            \qtab \tab (s_3, v_2) \\
    \tab = (s_1, v_1) \Leftarrow \pg{bx_1}{s}{construct\_dummy \ s}; \\
        \qtab (s_2, v_2) \Leftarrow \pg{bx_2}{v_1}{v}; \\
        \qtab (s_3, v_3) \Leftarrow \pg{bx_1}{s_1}{s_2}; \\
            \qtab \tab (s_3, v_2)$\\

The construction of $\pginline{bx_1 \circ bx_2}$ can be considered as the soul of the $pg$ function. The first two equalities comes from mentioned definitions and some basic transformations. The third one rewrites $v_1 \Leftarrow \getbx{bx_1}{s}$ into $(s_1, v_1) \Leftarrow \pg{bx_1}{s}{dummy}$. It is possible if we consider $\getbx{bx_1}{s}$ as the second element of $\pg{bx_1}{s}{dummy}$ where $dummy$ is a special value that makes the $put \, [\![bx_1]\!]$ valid. Due to GETPUT law, we can use $get \ s$ to update the source $s$ in the $put$ direction. Then it is feasible to construct a dummy from the source. The last equality changes $dummy$ by an application $construct\_dummy \ s$, and also substitutes $s$ in $(s_3, v_3) \Leftarrow \pg{bx_1}{s}{s_2}$ by $s_1$ which is the evaluated result of $\putbx{bx_1}{s}{construct\_dummy \ s}$. This transformation is possible due to the PUTPUT law. Then, $v_3$ in the result pair $(s_3,v_3)$ equals $dummy$. So we can realize that there is no loss information when computing a composition.

\subsection{Evaluation by pg}

By the definition of $pg$, we have:
$\pg{phead}{[1,2,3]}{100}\\
    \tab = (\putbx{phead}{[1,2,3]}{100}), \getbx{phead}{[1,2,3]})\\
    \tab = ([100,2,3], 1)$\\

On the other hand, we can evaluate $\pginline{phead}$ due to the construction of $pg$:
$\pg{phead}{[1,2,3]}{100}\\
    \tab = \pg{\rearrs{f_1}{f_2}{bx_s}}{[1,2,3]}{100}\\
    \tab = (s, v) \Leftarrow \pg{bx_s}{f_1 \ [1,2,3]}{100};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \pg{\rearrv{g_1}{g_2}{bx_v}}{(1,[2,3])}{100};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \{\\
        \qtab \tab (s, v) \Leftarrow \pg{bx_v}{(1,[2,3])}{g_1 \ 100};\\
        \qtab \tab (s, g_2 \ v)\\
        \qtab \};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \{\\
        \qtab \tab (s, v) \Leftarrow \pg{\product{Replace}{(Skip \ (\lambda \_.()))}}{(1,[2,3])}{((100,()))};\\
        \qtab \tab (s, g_2 \ v)\\
        \qtab \};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \{\\
        \qtab \tab (s, v) \Leftarrow \{\\
            \qtab \qtab (s_1, v_1) \Leftarrow \pg{Replace}{1}{100};\\
            \qtab \qtab (s_2, v_2) \Leftarrow \pg{(Skip \ (\lambda \_.()))}{[2,3]}{()};\\
            \qtab \qtab ((s_1,s_2), (v_1,v_2))\\
        \qtab \tab \};\\
        \qtab \tab (s, g_2 \ v)\\
        \qtab \};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \{\\
        \qtab \tab (s, v) \Leftarrow \{\\
            \qtab \qtab (s_1, v_1) \Leftarrow (100, 1);\\
            \qtab \qtab (s_2, v_2) \Leftarrow ([2,3], ());\\
            \qtab \qtab ((s_1,s_2), (v_1,v_2))\\
        \qtab \tab \};\\
        \qtab \tab (s, g_2 \ v)\\
        \qtab \};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow \{\\
        \qtab \tab (s, v) \Leftarrow ((100,[2,3]), (1,()))\\
        \qtab \tab (s, g_2 \ v)\\
        \qtab \};\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = (s, v) \Leftarrow ((100, [2,3]), 1);\\
        \qtab \tab (f_2 \ s, v)\\
    \tab = ([100,2,3], 1)$\\

We also have the evaluation of $\pginline{phead_1 \circ phead_2}$ as follows:

$\pg{phead_1 \circ phead_2}{[[1,2,3],[\,],[4,5]]}{100}\\
    \tab = (s_1, v_1) \Leftarrow \pg{phead_1}{[[1,2,3],[\,],[4,5]}{dummy};\\
        \qtab (s_2, v_2) \Leftarrow \pg{phead_2}{v_1}{100};\\
        \qtab (s_3, v_3) \Leftarrow \pg{phead_1}{s_1}{s_2};\\
            \qtab \tab (s_3, v_2)\\
    \tab = (s_1, v_1) \Leftarrow ([dummy,[\,],[4,5]], [1,2,3]);\\
        \qtab (s_2, v_2) \Leftarrow \pg{phead_2}{[1,2,3]}{100};\\
        \qtab (s_3, v_3) \Leftarrow \pg{phead_1}{s_1}{s_2};\\
            \qtab \tab (s_3, v_2)\\
    \tab = (s_1, v_1) \Leftarrow ([dummy,[\,],[4,5]], [1,2,3]);\\
        \qtab (s_2, v_2) \Leftarrow ([100,2,3], 1);\\
        \qtab (s_3, v_3) \Leftarrow \pg{phead_1}{[dummy,[\,],[4,5]]}{[100,2,3]};\\
            \qtab \tab (s_3, v_2)\\
    \tab = (s_1, v_1) \Leftarrow ([dummy,[\,],[4,5]], [1,2,3]);\\
        \qtab (s_2, v_2) \Leftarrow ([100,2,3], 1);\\
        \qtab (s_3, v_3) \Leftarrow ([[100,2,3],[\,],[4,5]], dummy);\\
            \qtab \tab (s_3, v_2)\\
    \tab = ([[100,2,3],[\,],[4,5]], 1)$\\

In the above evaluation, we do not clearly contruct what $dummy$ is. As we mentioned, $dummy$ is a special value which makes the first $\pginline{phead_1}$ valid. In this case, if we care about the type of $dummy$, it should be a list of integers. Thus, we can choose $dummy$ is an arbitrary list which has that type, for instance, an empty list or the head element of the source.

\section{cpg}

When evaluating $\pginline{bx_1 \circ bx_2}$, we realize that there are three $pg$ calls, of which twice for $\pginline{bx_1}$ and once for $\pginline{bx_2}$. If a given program is a left-associative composition, the number of $pg$ calls will be exponential. Therefore, the runtime inefficiency is inevitable.

In this section, we introduce a new function, $cpg$, accumulates changes in the source and the view to solve that problem. $\cpg{bx}{ks}{kv}{s}{v}$ is an extension of $\pg{bx}{s}{v}$ where $ks$ and $kv$ are continuations used to hold the modification information, and $s$ and $v$ are used to keep evaluated values. The output of this function is a 4-tuple $(ks, kv, s, v)$.

To be more convenient for presenting the definition of $cpg$ as well as the other functions later, we provide some following utility functions:

$\tab fst = \lambda (x_1,x_2). x_1\\
 \tab snd = \lambda (x_1,x_2). x_2\\
 \tab con = \lambda ks_1. \lambda ks_2. \lambda x. ((ks_1 \ x),(ks_2 \ x))$\\

\begin{definition}
$\cpg{bx}{ks}{kv}{s}{v}$

$\cpg{Skip \ h}{ks}{kv}{s}{v} = \text{ if } h \ s = v \text{ then } (ks, kv, s, v) \text{ else fail}$\\

$\cpg{Replace}{ks}{kv}{s}{v} = (kv, ks, v, s)$\\

$\cpg{\product{bx_1}{bx_2}}{ks}{kv}{s}{v} =\\
    \tab (ks_1, kv_1, s_1, v_1) \Leftarrow \cpg{bx_1}{fst \circ ks}{fst \circ kv}{fst \ s}{fst \ v};\\
    \tab (ks_2, kv_2, s_2, v_2) \Leftarrow \cpg{bx_2}{snd \circ ks}{snd \circ kv}{snd \ s}{snd \ v};\\
    \qtab (con \ ks_1 \ ks_2, con \ kv_1 \ kv_2, (s_1,s_2), (v_1,v_2))$\\

$\cpg{RearrS \ f_1 \ f_2 \ bx}{ks}{kv}{s}{v} =\\
    \tab (ks, kv, s, v) \Leftarrow \cpg{bx}{f_1 \circ ks}{kv}{f_1 \ s}{v};\\
    \qtab (f_2 \circ ks, kv, s, v)$\\

$\cpg{RearrV \ g_1 \ g_2 \ bx}{ks}{kv}{s}{v} =\\
    \tab (ks, kv, s, v) \Leftarrow \cpg{bx}{ks}{g_1 \circ kv}{s}{g_1 \ v};\\
    \qtab (ks, g_2 \circ kv, ks, g_2 \ v)$\\

$\cpg{Case \ cond_{sv} \ cond_{s} \ bx_1 \ bx_2}{ks}{kv}{s}{v} =\\
    \tab \text{if} \ cond_{sv} \ s \ v \ \&\& \ cond_{s} \ s\\
    \tab \text{then} \ (ks, kv, s', v') \Leftarrow \cpg{bx_1}{ks}{kv}{s}{v}\\
    \tab \text{else} \ (ks, kv, s', v') \Leftarrow \cpg{bx_2}{ks}{kv}{s}{v}\\
    \tab \text{fi} \ cond_{s} \ s' \ \&\& \ cond_{sv} s v'; \ \text{return} \ (ks, kv, s', v')$\\

$\cpg{bx_1 \circ bx_2}{ks}{kv}{s}{v} =\\
    \tab (ks_1, kv_1, s_1, v_1) \Leftarrow \cpg{bx_1}{ks}{id}{s}{construct\_dummy \ s};\\
    \tab (ks_2, kv_2, s_2, v_2) \Leftarrow \cpg{bx_2}{kv_1}{kv}{v_1}{v};\\
        \qtab (ks_1 \circ ks_2, kv_2,  ks_1 \ s_2, v_2)$
\end{definition}

Apart from the last construction, the others are quite similar to the corresponding ones of $pg$, but have some updates over the source and the view on accumulative functions $ks$ and $kv$ respectively.

For $\cpginline{bx_1 \circ bx_2}$, there are only two $cpg$ calls. The first call $\cpginline{bx_1}$ requires parameter $(ks, id, s, construct\_dummy \ s)$ where $s$ and $ks$ are corresponding to the source and the update over source. Because there is no real view here, we need to construct a dummy from the source. Then the continuation updating on this dummy should be initiated as an identity function. The first $cpg$ call is assigned to a 4-tuple $(ks_1, kv_1, s_1, v_1)$ where $s_1$ is redundant because it is not used in the later evaluation process. Some computations to get $s_1$ are seen as redundant. Such values and computations have negative impacts on the runtime as well as the memory allocation in the system. In the next assigment, a 4-tuple $(ks_2, kv_2, s_2, v_2)$ is assigned by the second $cpg$ call which uses the input as $(kv_1, kv, v_1, v)$ where $kv_1$ and $v_1$ are obtained from the result of the first assignment, and $kv$ and $v$ come from the input. It is relatively similar to the second $pg$ call assignment in $\pginline{bx_1 \circ bx_2}$. After two $cpg$ calls, a function application, $ks_1 \ s_2$, is used to produce the updated source instead of calling $\cpginline{bx_1}$ one more time like in $\pginline{bx_1 \circ bx_2}$.

Suppose that we have a source $s_0$ and a view $v_0$. The pair of the updated source and view $(s, v)$ where $s = \putbx{bx}{s_0}{v_0}$ and $v = \getbx{bx}{s_0}$ can be obtained using $cpg$ as follows:

    $\tab s \Leftarrow s_0; v \Leftarrow v_0;\\
    \tab (ks, kv, s, v) \Leftarrow \cpg{bx}{\lambda \_.s}{id}{s}{v};\\
        \qtab (s; v)$

In general, the begining of a continuation should be an identity function. However, to be able to use the function application to get the result of $\cpginline{bx_1 \circ bx_2}$, the accumulative function on the source $s$ needs to be initiated as a constant function $\lambda \_.s$.

Suppose the begining of continuations $ks$ and $kv$ are $ks_0$ and $id$ respectively. Let's consider $\cpg{phead_1 \circ phead_2}{ks_0}{id}{s}{v}$ where $s = [[1,2,3], [\,], [4,5]]$ and $v = 100$.\\ 
After the first two assignments in the definition of $cpg$ for the composition, we have:\\ 
    $\tab ks_1 = f_2 \circ (con \ (fst \circ g_1 \circ id) \ (snd \circ f_1 \circ ks_0))\\
    \tab s_2 = [100,2,3]$\\
where $f_1 = \lambda (s::ss).(s,ss)$, $f_2 = \lambda (s,ss).(s::ss)$, $g_1 = \lambda v.(v,())$\\
Then:\\ 
$\tab ks_1 \ s_2 \\ 
\tab = (f_2 \circ (con \ (fst \circ g_1 \circ id) \ (snd \circ f_1 \circ ks_0))) \ s_2 \\
\tab = f_2 \ (\ (fst(g_1(id(s_2))) \ , \ snd(f_1(ks_0(s_2))))\ )\\
\tab = fst(g_1(id(s_2))) :: snd(f_1(ks_0(s_2)))\\
\tab = [100,2,3] :: snd(f_1(ks_0([100,2,3])))$

If $ks_0$ is an identity function, $ks_1 \ s_2 = [100,2,3] :: [2,3]$. This is an unexpected result when we target it to be the updated source. If $ks_0 = \lambda \_.s$ where $s = [[1,2,3], [\,], [4,5]]$, $ks_1 \ s_2 = [100,2,3] :: [[\,], [4,5]] = [[100,2,3], [\,], [4,5]]$. This time, the result is what we want to see.

Through the above example, using the continuation $ks$ as a constant function at the beginning contributes to keep the unchanged parts in the source.


\section{kpg}

In the previous section, we have known that there are some variables which are evaluated but not used later when evaluating $\cpginline{bx_1 \circ bx_2}$. Now we introduce $kpg$, an extension of $cpg$, for keeping away such redundant computations. 
While $cpg$ evaluate values eagerly, $kpg$ does the opposite. Every values are evaluated lazily in a computation of $kpg$. The input of $\kpginline{bx}$ is expanded to a 6-tuple $(ks, kv, ks', kv', s, v)$ where $ks$ and $kv$ keep the modifcation information, $s$ and $v$ hold evaluated values, and $ks'$ and $kv'$ are used for lazy evaluation of actual values. The output of this function is also a 6-tuple $(ks, kv, ks', kv', s, v)$.\\

Suppose that we have a source $s_0$ and a view $v_0$. The pair of the updated source and view $(s, v)$ where $s = \putbx{bx}{s_0}{v_0}$ and $v = \getbx{bx}{s_0}$ can be obtained using $kpg$ as follows:

    $\tab s \Leftarrow s_0; v \Leftarrow v_0;\\
    \tab (ks, kv, ks', kv', s, v) \Leftarrow \kpg{bx}{\lambda \_.s}{id}{id}{id}{s}{v};\\
        \qtab (ks' \ s; kv' \ v)$

The begining of accumulative functions $ks'$ and $kv'$ are set as identity, while $ks$ and $kv$ are initiated as the same with the corresponding ones in $cpg$.

\begin{definition}
$\kpg{bx}{ks}{kv}{ks'}{kv'}{s}{v}$

$\kpg{Skip \ h}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab s \Leftarrow ks' \ s; \quad v \Leftarrow kv' \ v;\\
    \tab ks' \Leftarrow id; \quad kv' \Leftarrow id;\\
    \tab \text{if} \ h \ s = v \ \text{then} \ (ks, kv, ks', kv', s, v) \ \text{else fail}$\\

$\kpg{Replace}{ks}{kv}{ks'}{kv'}{s}{v} = (kv, ks, kv', ks', v, s)$\\

$\kpg{\product{bx_1}{bx_2}}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab s \Leftarrow ks' \ s; \quad v \Leftarrow kv' \ v;\\
    \tab ks' \Leftarrow id; \quad kv' \Leftarrow id;\\
    \tab (ks_1, kv_1, ks_1', kv_1', s_1, v_1) \Leftarrow \kpg{bx_1}{fst \circ ks}{fst \circ kv}{fst \circ ks'}{fst \circ kv'}{s}{v};\\
    \tab (ks_2, kv_2, ks_2', kv_2', s_2, v_2) \Leftarrow \kpg{bx_2}{snd \circ ks}{snd \circ kv}{snd \circ ks'}{snd \circ kv'}{s}{v};\\
    \tab ( con \ ks_1 \ ks_2, con \ kv_1 \ kv_2, \\
    \tab con \ (ks_1' \circ fst) \ (ks_2' \circ snd), con \ (kv_1' \circ fst) \ (kv_2' \circ snd), \\
    \tab (s_1, s_2), (v_1,v_2))$\\

$\kpg{RearrS \ f_1 \ f_2 \ bx}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab (ks, kv, ks', kv', s, v) \Leftarrow \kpg{bx}{f_1 \circ ks}{kv}{f_1 \circ ks'}{kv'}{s}{v};\\
    \qtab (f_2 \circ ks, kv, f_2 \circ ks', kv', s, v)$\\

$\kpg{RearrV \ g_1 \ g_2 \ bx}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab (ks, kv, ks', kv', s, v) \Leftarrow \kpg{bx}{ks}{g_1 \circ kv}{ks'}{g_1 \circ kv'}{s}{v};\\
    \qtab (ks, g_2 \circ kv, ks', g_2 \circ kv', s, v)$\\

$\kpg{Case \ cond_{sv} \ cond_{s} \ bx_1 \ bx_2}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab s \Leftarrow ks' \ s; \tab v \Leftarrow kv' \ v;\\
    \tab ks' \Leftarrow id ; \tab kv' \Leftarrow id;\\
    \tab \text{if} \ cond_{sv} \ s \ v \&\& \ cond_{s} \ s\\
    \tab \text{then} \ (ks, kv, ks', kv', s', v') \Leftarrow \kpg{bx_1}{ks}{kv}{ks'}{kv'}{s}{v}\\
    \tab \text{else} \ (ks, kv, ks', kv', s', v') \Leftarrow \kpg{bx_2}{ks}{kv}{ks'}{kv'}{s}{v}\\
    \tab \text{fi} \ cond_s \ (ks' \ s') \ \&\& \ cond_{sv} \ s \ (kv' v'); \ \text{return} \ (ks, kv, ks', kv', s', v')$\\

$\kpg{bx_1 \circ bx_2}{ks}{kv}{ks'}{kv'}{s}{v} =\\
    \tab (ks_1, kv_1, \underline{ks_1'}, kv_1', \underline{s_1}, v_1) \Leftarrow \kpg{bx_1}{ks}{id}{ks'}{id}{s}{construct\_dummy \ s};\\
    \tab (ks_2, kv_2, ks_2', kv_2', s_2, v_2) \Leftarrow \kpg{bx_2}{kv_1}{kv}{kv_1'}{kv'}{v_1}{v};\\
    \qtab (ks_1 \circ ks_2, kv_2, ks_1 \circ ks_2', kv_2', s_2, v_2)$
\end{definition}

In this construction of $kpg$, $s$ and $v$ hold actual values only in case of $Skip$ and $Case$. Except them, the functions for computation will be kept in $ks'$ and $kv'$.
    
When evaluating $\kpginline{bx_1 \circ bx_2}$, $ks_1'$ and $s_1$ in the result of the first assignment are still redundant but they are not evaluated. 

In $\kpginline{bx_1 \ prod \ bx_2}$, the evaluation of $ks'$ and $kv'$ will be done indendently in two assingments using $\kpginline{bx_1}$ and $\kpginline{bx_2}$. There may be some recomputations in $fst \circ ks'$ and $snd \circ ks'$ as well as $fst \circ kv'$ and $snd \circ kv'$. It is possible to evaluate actual values in $s$ and $v$ before calling $\kpginline{bx_1}$ to remove the redundancy like that.

\section{xpg}

So far, when computing a composition, we only recursively call an unique function, either $pg$ or $cpg$ or $kpg$. To be more flexible, we make a new extension, $xpg$, allowing to call external functions.

\begin{definition}
$\xpg{bx}{s}{v}$

$\xpg{bx}{s}{v} = \text{same with } pg \text{ if } bx \neq bx_1 \circ bx_2$

$\xpg{bx_1 \circ bx_2}{s}{v} =\\
    \tab (ks_1,kv_1, ks_1', kv_1', s_1, v_1) \Leftarrow \kpg{bx_1}{\lambda \_.s}{id}{id}{id}{s}{construct\_dummy \ s};\\
    \tab (s_2, v_2) \Leftarrow \xpg{bx_2}{kv_1' \ v_1}{v};\\
    \qtab (ks_1 \ s_2, v_2)$
\end{definition}

Similar to $pg$, $\xpginline{bx}$ accepts a pair of the source and the view $(s,v)$ to produce the new pair. The constructions of $\xpginline{bx}$ when $bx$ is not a composition are the same as the ones of $\pginline{bx}$. Note that, $xpg$ is called recursively instead of $pg$. For $\xpginline{bx_1 \circ bx_2}$, we use two function calls and a function application to calculate the result. The first call and the function application come from $kpg$ approaches, while the second call is based on $pg$ approach.

\section{Experiment}

This section describes the experiments involving $minbigul$, $pg$, $cpg$, $kpg$ and $xpg$. The number of function calls, the evaluation time and the memory allocation are considered in each test.

\subsection{Experiment environment}
We implemented 5 approaches with OCaml 4.07.1 in the same environment as follows: macOS 10.14.6, processor Intel Core i7 (2.6 GHz), RAM 16 GB 2400 MHz DDR4. The OCaml runtime system options and garbage collection parameters are set as default.  

\subsection{Test cases}
We are conducted tests on 5 cases, including many composition styles such as left or right associative, non-recursive or recursive. Table \ref{tab:test-cases} shows more details on these cases.

\begin{table}[]
    \centering
    \caption{Test cases}
    \label{tab:test-cases}
    \begin{tabular*}{\textwidth}{|c @{\extracolsep{\fill}}|l|l|l|c|c|c|c|}
        \hline
        \multirow{2}{*}{No} & \multicolumn{1}{c|}{\multirow{2}{*}{Name}} & \multicolumn{1}{c|}{\multirow{2}{*}{Associative}} & \multicolumn{1}{c|}{\multirow{2}{*}{Recursive}} & \multicolumn{2}{c|}{Input} & \multicolumn{2}{c|}{Output} \\ \cline{5-8} 
        & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{$s_0$} & \multicolumn{1}{c|}{$v_0$} & \multicolumn{1}{c|}{$s_r$} & \multicolumn{1}{c|}{$v_r$} \\ \hline
        1 & lassoc-comp-replace & left & no & 1 & 100 & 100 & 1 \\ \hline
        2 & rassoc-comp-replace & right & no & 1 & 100 & 100 & 1 \\ \hline
        3 & lassoc-comp-phead & left & no & $\underbrace{[[\ldots[1]\ldots]]}_{\text{n+1 times}}$ & 100 & $\underbrace{[[\ldots[100]\ldots]]}_{\text{n+1 times}}$ & 1 \\ \hline
        4 & rassoc-comp-phead & right & no & $\underbrace{[[\ldots[1]\ldots]]}_{\text{n+1 times}}$ & 100 & $\underbrace{[[\ldots[100]\ldots]]}_{\text{n+1 times}}$ & 1 \\ \hline
        5 & breverse & left/right & yes & [1..n] & [1..n] & [n..1] & [n..1] \\ \hline
    \end{tabular*}
\end{table}

In table \ref{tab:test-cases}, $s_r$ and $v_r$ are respectively updated source and view which are produced by applying $put$ and $get$ on original source $s_0$ and original view $v_0$. This means: $s_r = \putbx{bx}{s_0}{v_0}$ and $v_r = \getbx{bx}{s_0}$, where $bx$ is one of the 5 cases mentioned in the table. Note that the results $s_r$ and $v_r$ do not depend on the associative style of the composition.\\

The first 4 test cases simply use $n$ compose operators to make a composition of $n + 1$ similar $BX$ programs which are non-recursive. For example, \textit{lassoc-comp-replace}, left-associative composition of $Replace$s, looks like $(\ldots((Replace \circ Replace) \circ Replace) \circ \ldots \circ Replace) \circ Replace$, while \textit{rassoc-comp-replace}, right-associative composition of $Replace$s, is like $Replace \circ (Replace \circ (Replace \circ \ldots \circ (Replace \circ Replace)\ldots))$, where there are $n + 1 \ Replace$s in each case. \textit{lassoc-comp-phead} and \textit{rassoc-comp-phead} are similar to the above two.

In section 3, we defined a composition $phead \circ phead$ for updating the head element of the head element of a list of lists by using the view. Similarly, we can use the view to update head element in the nested lists with a composition of a specific number of $phead$s. For both \textit{lassoc-comp-phead} and \textit{rassoc-comp-phead}, we choose input view $v_0$ is 100 and input source $s_0$ is one of the smallest nested lists which make $put$ and $get$ directions on the composition valid.\\

The last test case, $bReverse$, is a recursive composition. It is defined in terms of $bFoldr$, a putback function for $foldr$ in BiGUL as well as minbigul. What we know about $foldr$, an important higher-order function on lists, is as follows:\\
    $\tab foldr :: (a \to b \to b) \to b \to [a] \to b\\
    \tab foldr \ f \ e \ [\,] = e\\
    \tab foldr \ f \ e \ (x:xs) = f \ x \ (foldr \ f \ e \ xs)$

We can define function $reverse$ on lists based on $foldr$:\\
    $\tab reverse \ [\,] = [\,]\\
    \tab reverse \ (x:xs) = snoc \ x \ (reverse \ xs)\\
    \tab reverse = foldr \ snoc \ [\,]$

Let's see the following definition of $bFoldr$ which is a restricted version of $lensFoldr$ in [?] without adaptive cases:

$\tab bFoldr :: (Show \ a, Show \ v) \Rightarrow BiGUL \ (a, v) \ v \to BiGUL \ ([a], v) \ v\\
\tab bFoldr \ bx =\\
    \qtab Case \ [\$(normal \ [\![ \lambda (x,\_) v \to null \ x ]\!] \ [\![ \lambda (x,\_) \to null \ x ]\!])\\
        \qtab \qtab \Longrightarrow \$(RearrV [| \lambda v \to ((),v) |])\$\\
            \qtab \qtab \qtab (Skip \ (const \ ())) \ `Prod \text{'} \ Replace\\
    \qtab \qtab, \$(normal \ [\![ \lambda (x,\_) v \to not \ (null \ x) ]\!] \ [\![ \lambda (x,\_) \to not \ (null \ x) ]\!])\\
        \qtab \qtab \Longrightarrow \$(RearrS \ [\![ \lambda ((x:xs), e) \to (x, (xs,e)) |])\$\\
            \qtab \qtab \qtab (Replace \ `Prod\text{'} \ bFoldr \ bx) \ \circ \ bx\\
    \qtab \qtab]\\$

The detailed explanation of $bFoldr$ are skipped. Like $phead$, the program equipvalent to the above $bFoldr$ is also provided in our OCaml system. In the second branch of $bFoldr$, there is a composition of two BX programs where the first requires a recursive call. Then this composition can be classified as either left or right associative type. However it will look like a composition of more BX programs at some point if we slow down to evaluate it. Note that the compose operator has a higher priority than the product operator. This leads to seemingly impossible to transform the above composition from left-associative style to right-associative style.

Suppose that we haved $bSnoc$, a bidirectional version of $snoc$, in BiGUL. Then $bReverse$ can defined as follows:

    $\tab bReverse :: Show \ a \Rightarrow BiGUL \ [a] \ [a]\\
    \tab bReverse =\\
        \qtab Case \ [ \$(adaptive \ [\![ \lambda s \ v \to length \ s \neq length \ v ]\!])\\
        \qtab \qtab \quad \lambda s \ v \to v\\
        \qtab \qtab , \$(normal \ [\![ \lambda s \ v \to True ]\!] \ [\![ \lambda s \to True ]\!])\\
        \qtab \qtab \quad \$(RearrS \ [\![ \lambda s \to (s,[\,]) ]\!])\$\\
            \qtab \qtab \qquad bFoldr \ bSnoc\\
       \qtab \qtab ]$

The above definition contains an adaptive branch and it only occurs when the lengths of the source and the view are different. If we restrict them as two lists whose same lengths, the case analysis will only evaluate the normal branch. For test case $breverse$ in table \ref{tab:test-cases}, we choose both $s_0$ and $v_0$ as lists from 1 to $n$. Then, the results $s_r$ and $v_r$ are the list from $n$ to 1. Explicitly, $\putbx{bReverse}{[1..n]}{[1..n]} = [n..1]$ and $\getbx{bReverse}{[1..n]} = [n..1]$. In $bReverse$, the number of compositions equals to the length of the source and the view.

\subsection{Results and discussions}

We will in turn consider the empirical results about the number of function calls, the evaluation time and the memory allocation.\\

Fig \ref{fig:count-calls} depicts the number of function calls including $put$, $get$, $pg$, $cpg$, $kpg$ and $xpg$ for each test case. From definitions of $put$, $cpg$, $kpg$ and $xpg$, we have No($cpg$) = No($kpg$) = No($xpg$) = No($put$) where No($f$) is the number of function call $f$. Here we consider that No($xpg$) in evaluating $\xpginline{bx_1 \circ bx_2}$ includes both the number of $kpg$s which are used in $\kpginline{bx_1}$ and the number of $xpg$s which are used in $\xpginline{bx_2}$.\\

For right-associative and non-recursive compositions (\textit{rassoc-comp-replace} and \textit{rassoc-comp-phead}), No($get$), No($put$) and No($pg$) are linear where No($get$) $<$ No($put$) $<$ No($pg$).\\

For left-associative and non-recursive compositions (\textit{lassoc-comp-replace} and \textit{lassoc-comp-phead}), No($put$) is still linear while No($get$) is quadratic and No($pg$) is under an exponential distribution. In this case, No($put$) $<$ No($get$) $<$ No($pg$).\\

For recursive composition (\textit{breverse}), the results still show that No($put$) $<$ No($get$) $<$ No($pg$) but all three are nonlinear. In case of \textit{breverse}, No($put$) is quadratic, No($get$) is cubic and No($pg$) is exponential.\\

\begin{figure}
    \centering
    \subfloat[\textit{lassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {number of calls},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.15,0.78)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/count-lassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=count_get]{\data};
                \addlegendentry{get};
                \addplot table[x=nComp,y=count_put]{\data};
                \addlegendentry{put};
                \addplot table[x=nComp,y=count_pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=count_xpg]{\data};
                \addlegendentry{cpg/kpg/xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.03,0.78)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/count-rassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=count_get]{\data};
                \addlegendentry{get};
                \addplot table[x=nComp,y=count_put]{\data};
                \addlegendentry{put};
                \addplot table[x=nComp,y=count_pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=count_xpg]{\data};
                \addlegendentry{cpg/kpg/xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{0mm}
    \subfloat[\textit{lassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {number of calls},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.15,0.78)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/count-lassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=count_get]{\data};
                \addlegendentry{get};
                \addplot table[x=nComp,y=count_put]{\data};
                \addlegendentry{put};
                \addplot table[x=nComp,y=count_pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=count_xpg]{\data};
                \addlegendentry{cpg/kpg/xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.03,0.78)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/count-rassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=count_get]{\data};
                \addlegendentry{get};
                \addplot table[x=nComp,y=count_put]{\data};
                \addlegendentry{put};
                \addplot table[x=nComp,y=count_pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=count_xpg]{\data};
                \addlegendentry{cpg/kpg/xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \vspace{2mm}
    \subfloat[\textit{breverse}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {number of calls},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.47,0.78)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/count-breverse.csv}\data
                \addplot table[x=nComp,y=count_get]{\data};
                \addlegendentry{get};
                \addplot table[x=nComp,y=count_put]{\data};
                \addlegendentry{put};
                \addplot table[x=nComp,y=count_pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=count_xpg]{\data};
                \addlegendentry{cpg/kpg/xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Number of calls}
    \label{fig:count-calls}
\end{figure}


\begin{figure}
    \centering
    \subfloat[\textit{lassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {evaluation time (s)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.2,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/time-lassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.03,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/time-rassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{0mm}
    \subfloat[\textit{lassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {evaluation time (s)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.2,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/time-lassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.03,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/time-rassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \vspace{2mm}
    \subfloat[\textit{breverse}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {evaluation time (s)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(1.03,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/time-breverse.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Evaluation time (s)}
    \label{fig:evaluation-time}
\end{figure}

Fig \ref{fig:evaluation-time} illustrates the evaluation times in 5 test cases.\\

$pg$ times are always exponential for both left-associative compositions (\textit{lassoc-comp-replace}, \textit{lassoc-comp-phead}) and recursive compositions (\textit{breverse}) since the number of $pg$s in these cases are under exponential distributions.\\

For left-associative and non-recursive compositions, $kpg$ times are approximate to $xpg$ times, and they are the most efficient. In case of \textit{lassoc-comp-replace}, $kpg$ time and $xpg$ time are linear, $cpg$ time and $minbigul$ time are nonlinear. They are quite reasonable because the data sizes are constant, No($get$) is quadractic for minbigul while there is a linear redundant evaluation in $cpg$. In case of \textit{lassoc-comp-phead}, since the data sizes are linear and the numbers of function calls are either linear or quadractic or exponential, all times are nonlinear\\

For right-associative and non-recursive compositions, $minbigul$, $pg$ and $xpg$ times are linear. In case of \textit{rassoc-comp-replace}, all times are small enough to consider all them as linear. In case of \textit{rassoc-comp-phead}, both $cpg$ and $kpg$ times are quadratic because the data sizes are linear and the number of redundant evaluations are also linear.\\

For recursive compositions (\textit{breverse}), all times should be nonlinear since there is no linear number of function calls.\\

\begin{figure}
    \centering
    \subfloat[\textit{lassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {memory allocation (MBytes)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.2,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/mem-lassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-replace}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.03,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/mem-rassoc-comp-replace.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{0mm}
    \subfloat[\textit{lassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {memory allocation (MBytes)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.2,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/mem-lassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \subfloat[\textit{rassoc-comp-phead}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.2,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/mem-rassoc-comp-phead.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};x
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \vspace{2mm}
    \subfloat[\textit{breverse}]{
        \begin{tikzpicture}
            \begin{axis}[
                xmode = normal,
                ymode = normal,
                xlabel = {number of compositions},
                ylabel = {memory allocation (MBytes)},
                width = 0.55\linewidth,
                legend style = {font=\scriptsize,at={(0.57,0.75)},anchor=west},
            ]
                \pgfplotstableread[col sep=comma]{csv/mem-breverse.csv}\data
                \addplot table[x=nComp,y=minbigul]{\data};
                \addlegendentry{minbigul};
                \addplot table[x=nComp,y=pg]{\data};
                \addlegendentry{pg};
                \addplot table[x=nComp,y=cpg]{\data};
                \addlegendentry{cpg};
                \addplot table[x=nComp,y=kpg]{\data};
                \addlegendentry{kpg};
                \addplot table[x=nComp,y=xpg]{\data};
                \addlegendentry{xpg};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Memory allocation (MBytes)}
    \label{fig:memory-allocation}
\end{figure}

Fig \ref{fig:memory-allocation} shows the memory usage which depends on the input size and number of compositions. In general, $minbigul$ uses less memory than the others for non-recursive compositions (all tests except \textit{breverse}). $pg$ only uses memory efficient when handling right-associative compositions. Also for evaluating these  compositions, both $cpg$ and $kpg$ are worst in memory allocation. For recursive compositions (\textit{breverse}), $minbigul$ uses significantly more memory than $kpg$ as well as $xpg$.

\begin{table}[]
    \centering
    \caption{Comparison}
    \label{tab:comparison}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|l|l|l|l|}
            \hline
            \multicolumn{1}{|c|}{Name} & \multicolumn{1}{c|}{Properties} & \multicolumn{1}{c|}{Evaluation time order} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Memory allocation order\\ (stack\_overflow point / 100000)\end{tabular}} \\ \hline
            lassoc-comp-replace & l, NR & xpg $\sim$ kpg $<$ cpg $<$ minbigul $<$ pg & minbigul $<$ cpg $<$ xpg $\sim$ kpg (95299) $<$ pg (ND) \\ \hline
            rassoc-comp-replace & r, NR & minbigul $<$ pg $<$ xpg $<$ cpg $<$ kpg & minbigul $<$ pg $<$ xpg $<$ cpg (95299) $<$ kpg (80638) \\ \hline
            lassoc-comp-phead & l, NR & xpg $<$ kpg $<$ minbigul $<$ cpg $<$ pg & minbigul $<$ xpg $\sim$ kpg (80638) $<$ cpg (ND) $<$ pg (ND) \\ \hline
            rassoc-comp-phead & r, NR & minbigul $<$ pg $<$ xpg $<$ cpg $<$ kpg & minbigul $<$ pg $<$ xpg $<$ cpg (43680) $<$ kpg (61665) \\ \hline
            breverse & l/r, R & xpg $<$ kpg $<$ minbigul $<$ cpg $<$ pg & xpg (ND) $<$ kpg (ND) $<$ cpg (ND) $<$ minbigul (ND) $<$ pg (ND) \\ \hline
            \multicolumn{4}{r}{} \\
            \multicolumn{4}{r}{stack\_overflow point (default: $>$ 100000): can not evaluate a program if the number of compositions is larger than this point} \\
            \multicolumn{4}{r}{best $< \ldots < \ldots <$ worst} \\
            \multicolumn{4}{r}{l/r: left/right associative} \\
            \multicolumn{4}{r}{NR/R: non-recursive/recursive} \\
            \multicolumn{4}{r}{ND: not determined}
        \end{tabular}%
    }
\end{table}

Table \ref{tab:comparison} indicates a general comparison of the above results over the evaluation time and the memory allocation. This table provides some additional information about the point where a stack overflow error occurs in our OCaml system. We conducted tests while increasing the number of compositions from 10 to 100000. By default, the stack overflow point in the table is larger than 100000. In some cases, we limited the number of compositions because the corresponding evaluation times are too long. Then the above points are not determined.  

\section{Related Work}



\newpage


\section{Conclusion and Future Work}


% From sample code
% 
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
\bibitem{ref_article1}
Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

\bibitem{ref_lncs_1}
Author, F., Author, S.: Title of a proceedings paper. In: Editor,
F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
Springer, Heidelberg (2016). \doi{10.10007/1234567890}

\bibitem{ref_book1}
Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
Location (1999)

\bibitem{ref_proc1}
Author, A.-B.: Contribution title. In: 9th International Proceedings
on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{ref_url1}
LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
Oct 2017
\end{thebibliography}
\end{document}







\subsubsection{Sample Heading (Third Level)} Only two levels of
headings should be numbered. Lower level headings remain unnumbered;
they are formatted as run-in headings.

\paragraph{Sample Heading (Fourth Level)}
The contribution should contain no more than four levels of
headings. Table~\ref{tab1} gives a summary of all heading levels.

\begin{table}
\caption{Table captions should be placed above the
tables.}\label{tab1}
\begin{tabular}{|l|l|l|}
\hline
Heading level &  Example & Font size and style\\
\hline
Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
\hline
\end{tabular}
\end{table}


\noindent Displayed equations are centered and set on a separate
line.
\begin{equation}
x + y = z
\end{equation}
Please try to avoid rasterized images for line-art diagrams and
schemas. Whenever possible, use vector graphics instead (see
Fig.~\ref{fig_1}).

\begin{figure}
\includegraphics[width=\textwidth]{fig_1.eps}
\caption{A figure caption is always placed below the illustration.
Please note that short captions are centered, while long ones are
justified by the macro package automatically.} \label{fig_1}
\end{figure}

\begin{theorem}
This is a sample theorem. The run-in heading is set in bold, while
the following text appears in italics. Definitions, lemmas,
propositions, and corollaries are styled the same way.
\end{theorem}
%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
\begin{proof}
Proofs, examples, and remarks have the initial word in italics,
while the following text appears in normal font.
\end{proof}
For citations of references, we prefer the use of square brackets
and consecutive numbers. Citations using labels or the author/year
convention are also acceptable. The following bibliography provides
a sample reference list with entries for journal
articles~\cite{ref_article1}, an LNCS chapter~\cite{ref_lncs_1}, a
book~\cite{ref_book1}, proceedings without editors~\cite{ref_proc1},
and a homepage~\cite{ref_url1}. Multiple citations are grouped
\cite{ref_article1,ref_lncs_1,ref_book1},
\cite{ref_article1,ref_book1,ref_proc1,ref_url1}.
%


\section{Remove?:Reversible langauge: Rwhile}

% Maybe we should skip

\begin{itemize}
\item Usually programs receives inputs and produces outputs. It is impossible to produce inputs from outputs in general. Obtaining the inverse program of a program is difficult.
\item Using reversible language, we can obtain inverse programs easily.
\item Explanation of Rwhile: we need fi-condition.
\item syntax, how to work.
\end{itemize}

\section{Remove?:First approach}

% We should skip this 

\begin{itemize}
\item Make put and get to be reversible. We need garbages (g) to keep lost infomation after evaluation.
\item put$_{REV}$ = s * v $\to$ s * gb
\item get$_{REV}$ = s $\to$ v * gb
\item introduce (put$_{REV}^{-1}$: s * gb $\to$ s * v) and (get$_{REV}^{-1}$:v * gb $\to$ s)
\item \textcolor{red}{(Missing part?)} Relationship between put$_{REV}$, get$_{REV}$, put$_{REV}^{-1}$, get$_{REV}^{-1}$ 
\end{itemize}

$\putrev{Skip \ h}{s}{v} =  \sif{h \ s = v}{(s, v)}{\text{fail}}$

$\putrev{Replace}{s}{v} = (v, s)$

$\putrev{\product{bx_1}{bx_2}}{(s_1 :: s_2)}{(v_1 :: v_2)} =\\
    \tab (s_1, gb_1) \Leftarrow \putrev{bx_1}{s_1}{v_1};\\
    \tab (s_2, gb_2) \Leftarrow \putrev{bx_2}{s_2}{v_2};\\
        \qtab (s_1 :: s_2, gb_1 :: gb_2)$

$\putrev{\rearrs{f_1}{f_2}{bx}}{s}{v} =\\
    \tab (s_1, gb_1) \Leftarrow \putrev{bx}{(f_1 \ s)}{v};\\
        \qtab (f_2 \ s_1, gb_1)$

$\putrev{\rearrv{g_1}{g_2}{bx}}{s}{v} =\\
    \tab (s_1, gb_1) \Leftarrow \putrev{bx}{s}{(g_1 \ v)};\\
        \qtab (s_1, gb_1)$

$\putrev{\casebx{cond_{sv}}{cond_{s}}{bx_1}{bx_2}}{s}{v} =\\
    \tab \text{if} \ cond_{sv} \ s \ v\\
    \tab \text{then} \ (s', gb) \Leftarrow \putrev{bx_1}{s}{v};\\
    \tab \text{else} \ (s', gb) \Leftarrow \putrev{bx_2}{s}{v};\\
    \tab \text{fi} \ cond_{s} \ s'; \ \text{return} \ (s', gb)$

$\putrev{bx_1 \circ bx_2}{s}{v} =\\
    \tab (s_1, gb_1) \Leftarrow \getrev{bx_1}{s};\\
    \tab (s_2, gb_2) \Leftarrow \putrev{bx_2}{s_1}{v};\\
    \tab (s_3, gb_3) \Leftarrow \putrev{bx_1}{s}{s_2} \ \text{in (* need to copy s *)}\\
        \qtab (s_3, gb_1 :: gb_2 :: gb_3)$

\vspace{5mm}

$\getrev{Skip \ h}{s} = {(h \ s, s)}$

$\getrev{Replace}{s} = (s, \textcolor{red}{\text{Nil}})$

$\getrev{\product{bx_1}{bx_2}}{(s_1 :: s_2)} = \\
    \tab (v_1, gb_1) \Leftarrow \getrev{bx_1}{s_1};\\
    \tab (v_2, gb_2) \Leftarrow \getrev{bx_2}{s_2};\\
        \qtab (v_1 :: v_2, gb_1 :: gb_2)$

$\getrev{\rearrs{f_1}{f_2}{bx}}{s}{v} =\\
    \tab (v_1, gb_1) \Leftarrow \getrev{bx}{(f_1 \ s)};\\
        \qtab (v_1, gb_1)$

$\getrev{\rearrv{g_1}{g_2}{bx}}{s}{v} =\\
    \tab (v_1, gb_1) \Leftarrow \getrev{bx}{s};\\
        \qtab (g_2 \ v_1, gb_1)$

$\getrev{\casebx{cond_{sv}}{cond_{s}}{bx_1}{bx_2}}{s} =\\
    \tab \text{if} \ cond_{s} \ s\\
    \tab \text{then} \ (v', gb) \Leftarrow \getrev{bx_1}{s};\\
    \tab \text{else} \ (v', gb) \Leftarrow \getrev{bx_2}{s};\\
    \tab \text{fi} \ cond_{sv} \ s \ v'; \ \text{return} \ (v', gb)$

$\getrev{bx_1 \circ bx_2}{s}{v} =\\
    \tab (v_1, gb_1) \Leftarrow \getrev{bx_1}{s};\\
    \tab (v_2, gb_2) \Leftarrow \getrev{bx_1}{s};\\
        \qtab (v_2, gb_1 :: gb_2)$

\textcolor{red}{If we use Rwhile for target language, we do not need to introduce inverse.}
